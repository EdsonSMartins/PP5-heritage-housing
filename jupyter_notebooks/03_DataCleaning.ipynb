{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Cleaning Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Further data exploration\n",
        "* Evaluate missing data\n",
        "* Decide on imputation methods for missing data\n",
        "* Split the data into Train and Test sets.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/house_prices_records.csv \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate cleaned Train and Test sets, saved under outputs/datasets/cleaned \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* CRISP-DM: *Data Understanding/Preparation* \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import all necessary packages and libraries for the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from ydata_profiling import ProfileReport\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "from sklearn.pipeline import Pipeline\n",
        "from feature_engine.selection import DropFeatures\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "from feature_engine.imputation import CategoricalImputer\n",
        "from feature_engine.imputation import ArbitraryNumberImputer\n",
        "sns.set(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Collected Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_raw_path = \"outputs/datasets/collection/house_prices_records.csv\"\n",
        "df = pd.read_csv(df_raw_path)\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reviewing the list of columns with missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
        "vars_with_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "if vars_with_missing_data:\n",
        "    profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
        "    profile.to_notebook_iframe()\n",
        "else:\n",
        "    print(\"There are no variables with missing data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observation:\n",
        "* in total 9 columns are missing data \n",
        "* a total of approx.. 26% of cells are missing data.\n",
        "* some of the variables with missing values also have too many zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Correlation and PPS Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Custom functions used to calculate the Pearson and Spearman coefficients, and the PPS are taken from Code Institute's \"Churnometer\" walkthrough project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def heatmap_corr(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=bool)\n",
        "        mask[np.triu_indices_from(mask)] = True\n",
        "        mask[abs(df) < threshold] = True\n",
        "\n",
        "        fig, axes = plt.subplots(figsize=figsize)\n",
        "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                    mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                    linewidth=0.5\n",
        "                    )\n",
        "        axes.set_yticklabels(df.columns, rotation=0)\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=bool)\n",
        "        mask[abs(df) < threshold] = True\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                         mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                         linewidth=0.05, linecolor='grey')\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "    df_corr_spearman = df.corr(method=\"spearman\")\n",
        "    df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "    pps_matrix_raw = pps.matrix(df)\n",
        "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "    pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "    print(pps_score_stats.round(3))\n",
        "\n",
        "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
        "                      figsize=(20, 12), font_annot=8):\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "    print(\"* Analyse multi-colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "    print(\"It evaluates monotonic relationship \\n\")\n",
        "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "          f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                  df_corr_spearman = df_corr_spearman,\n",
        "                  pps_matrix = pps_matrix,\n",
        "                  CorrThreshold = 0.3, PPS_Threshold = 0.2,\n",
        "                  figsize=(12,10), font_annot = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assessing Missing Data Levels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following custom function was taken from CI walkthrough project 2. Its purpose is to list the variables with missing data with more details in relation to the missing data values and overall percentage in comparison to the whole data set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def EvaluateMissingData(df):\n",
        "    missing_data_absolute = df.isnull().sum()\n",
        "    missing_data_percentage = round(missing_data_absolute/len(df)*100, 2)\n",
        "    df_missing_data = (pd.DataFrame(\n",
        "        data={\"RowsWithMissingData\": missing_data_absolute,\n",
        "              \"PercentageOfDataset\": missing_data_percentage,\n",
        "              \"DataType\": df.dtypes}\n",
        "    )\n",
        "                       .sort_values(by=['PercentageOfDataset'], ascending=False)\n",
        "                       .query(\"PercentageOfDataset > 0\")\n",
        "                      )\n",
        "    return df_missing_data\n",
        "\n",
        "EvaluateMissingData(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning Spreadsheet Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After reviewing the missing data levels and analysis of variables in the context of the business case, we want to preserve as much of it as possible and instead of dropping data instances or deleting variables from the data set. \n",
        "\n",
        "The following approaches will be tried to deal with missing data. A spreadsheet was used to record potential data cleaning approaches during development Heritage Housing Spreadsheet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Variables | Observations | Possible Approach |\n",
        "| :---------:| :---------: | :--------: |\n",
        "| 'EnclosedPorch' | About 90% of data missing. The reason could be the non existence of a enclosed porch or data may not have been inputed due to user error | DROP |\n",
        "| 'WoodDeckSF' | Also has a large portion of missing data (89.38%). The reason could be the non existence of a wood deck or data may not have been inputed due to user error | DROP |\n",
        "| '2ndFlrSF' | There is a possibility that some houses do not have a second floor - 53.5% of data is a zero. Therefore one may assume that imputing the null values with 0 would add value.   | Arbitrary Number Imputation |\n",
        "| 'MasVnrArea' | Most values for this variable are 0 indicating that there is no masonry veneer. Accordingly, we can assume that missing variables indicate the absence of a masonry veneer, so we can impute 0 as a value here. | Arbitrary Number Imputation |\n",
        "| 'BedroomAbvGr'| The data have a mean of 2.9, a median of 3 and a std of 0.8. Noted that the distribution look fairly close to the normal distribution| Median Imputation |\n",
        "| 'GarageYrBlt' | Data could be missing for some houses that do not have garages, therefore this data may have intentionally been missed. Although we could just imput zero to add value, this would not be valid because we cannot imput a year to a garage that does not exist.  | Median Imputation or Drop|\n",
        "| 'LotFrontage' |  By checking the distribution of this variable, we found that it has a slight positive skew and strong positive kurtosis. It is therefore not normally distributed and we should impute the median. | Median Imputation |\n",
        "| 'GarageFinish' | A little over 10% of the data is missing because some entries are 0, meaning there is no garage. A few approaches should be consider here such as use the machine model to predict  the GarageFinish based on other available variables present but for now we will simply impute an arbitrary value of \"unf\" to represent unfinished.  | Categorical Imputation ('unf') |\n",
        "| 'BsmtFinType1' | Similar reasons to those listed for 'GarageFinish'. For now, we will simply impute an arbitrary value of \"unf\" to represent unfinished.| Categorical Imputation ('unf') |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dealing with Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The function used to assess the effect of the cleaning process is taken from Code Institute's lessons on Feature Engineering Module:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def DataCleaningEffect(df_original,df_cleaned,variables_applied_with_method):\n",
        "\n",
        "  flag_count=1 # Indicate plot number\n",
        "  \n",
        "  # distinguish between numerical and categorical variables\n",
        "  categorical_variables = df_original.select_dtypes(exclude=['number']).columns \n",
        "\n",
        "  # scan over variables, \n",
        "    # first on variables that you applied the method\n",
        "    # if the variable is a numerical plot, a histogram if categorical plot a barplot\n",
        "  for set_of_variables in [variables_applied_with_method]:\n",
        "    print(\"\\n=====================================================================================\")\n",
        "    print(f\"* Distribution Effect Analysis After Data Cleaning Method in the following variables:\")\n",
        "    print(f\"{set_of_variables} \\n\\n\")\n",
        "  \n",
        "\n",
        "    for var in set_of_variables:\n",
        "      if var in categorical_variables:  # it is categorical variable: barplot\n",
        "        \n",
        "        df1 = pd.DataFrame({\"Type\":\"Original\",\"Value\":df_original[var]})\n",
        "        df2 = pd.DataFrame({\"Type\":\"Cleaned\",\"Value\":df_cleaned[var]})\n",
        "        dfAux = pd.concat([df1, df2], axis=0)\n",
        "        fig , axes = plt.subplots(figsize=(15, 5))\n",
        "        sns.countplot(hue='Type', data=dfAux, x=\"Value\",palette=['#432371',\"#FAAE7B\"])\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.xticks(rotation=90)\n",
        "        plt.legend() \n",
        "\n",
        "      else: # it is numerical variable: histogram\n",
        "\n",
        "        fig , axes = plt.subplots(figsize=(10, 5))\n",
        "        sns.histplot(data=df_original, x=var, color=\"#432371\", label='Original', kde=True,element=\"step\", ax=axes)\n",
        "        sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\", label='Cleaned', kde=True,element=\"step\", ax=axes)\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.legend() \n",
        "\n",
        "      plt.show()\n",
        "      flag_count+= 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Cleaning Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Drop : ['EnclosedPorch', 'WoodDeckSF', 'GarageYrBlt']\n",
        "* Arbitrary Number Imputation : ['2ndFlrSF', 'MasVnrArea']\n",
        "* MeanMedian Imputation : ['BedroomAbvGr', 'LotFrontage']\n",
        "* Categorical Imputation : ['GarageFinish', 'BsmtFinType1']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Drop Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.selection import DropFeatures\n",
        "\n",
        "variables_method = ['EnclosedPorch', 'WoodDeckSF', 'GarageYrBlt' ]\n",
        "variables_method\n",
        "\n",
        "imputer = DropFeatures(features_to_drop=variables_method)\n",
        "df_method = imputer.fit_transform(df)\n",
        "df_method.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Arbitrary Number Imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.imputation import ArbitraryNumberImputer\n",
        "\n",
        "variables_method = ['2ndFlrSF', 'MasVnrArea']\n",
        "variables_method\n",
        "\n",
        "imputer = ArbitraryNumberImputer(arbitrary_number=0, variables=variables_method)\n",
        "df_method = imputer.fit_transform(df)\n",
        "\n",
        "DataCleaningEffect(df_original=df,\n",
        "                   df_cleaned=df_method,\n",
        "                   variables_applied_with_method=variables_method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MeanMedian Imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "variables_method = ['BedroomAbvGr', 'LotFrontage']\n",
        "variables_method\n",
        "\n",
        "\n",
        "imputer = MeanMedianImputer(imputation_method='median', variables=variables_method)\n",
        "                            \n",
        "df_method = imputer.fit_transform(df)\n",
        "\n",
        "DataCleaningEffect(df_original=df,\n",
        "                   df_cleaned=df_method,\n",
        "                   variables_applied_with_method=variables_method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Categorical Imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from feature_engine.imputation import CategoricalImputer\n",
        "\n",
        "variables_method = ['GarageFinish', 'BsmtFinType1']\n",
        "variables_method\n",
        "\n",
        "imputer = CategoricalImputer(imputation_method='missing', fill_value='Unf', variables=variables_method)\n",
        "df_method = imputer.fit_transform(df)\n",
        "\n",
        "DataCleaningEffect(df_original=df,\n",
        "                   df_cleaned=df_method,\n",
        "                   variables_applied_with_method=variables_method)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train and Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Next we split the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TrainSet, TestSet, _, __ = train_test_split(\n",
        "                                        df,\n",
        "                                        df['SalePrice'],\n",
        "                                        test_size=0.2,\n",
        "                                        random_state=0)\n",
        "\n",
        "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Now we apply the changes from the various imputation methods to the train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop Variables \n",
        "variables_method = ['EnclosedPorch', 'WoodDeckSF', 'GarageYrBlt']\n",
        "imputer = DropFeatures(features_to_drop=variables_method)\n",
        "imputer.fit(TrainSet)\n",
        "TrainSet, TestSet = imputer.transform(TrainSet), imputer.transform(TestSet)\n",
        "\n",
        "# Arbitrary Number Imputer \n",
        "variables_method = ['2ndFlrSF', 'MasVnrArea']\n",
        "imputer = ArbitraryNumberImputer(arbitrary_number=0, variables=variables_method)\n",
        "imputer.fit(TrainSet)\n",
        "TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)\n",
        "\n",
        "# MeanMedian Imputer\n",
        "variables_method = ['BedroomAbvGr', 'LotFrontage']\n",
        "imputer = MeanMedianImputer(imputation_method='median', variables=variables_method)\n",
        "imputer.fit(TrainSet)\n",
        "TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)\n",
        "\n",
        "# Categorical Imputation\n",
        "variables_method = ['BsmtFinType1', 'GarageFinish']\n",
        "imputer = CategoricalImputer(imputation_method='missing', fill_value='Unf', variables=variables_method)\n",
        "imputer.fit(TrainSet)\n",
        "TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "* Evaluate missing data one more time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_missing_data = EvaluateMissingData(TrainSet)\n",
        "print(f\"* There are {df_missing_data.shape[0]} variables with missing data \\n\")\n",
        "df_missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Cleaning Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_cleaning_pipeline = Pipeline([\n",
        "      ( 'DropFeatures', DropFeatures(features_to_drop=['EnclosedPorch', 'WoodDeckSF', 'GarageYrBlt']) ),\n",
        "      ( 'ArbitraryNumberImputer', ArbitraryNumberImputer(arbitrary_number=0, variables=['2ndFlrSF', 'MasVnrArea']) ),\n",
        "      ( 'MeanMedianImputer', MeanMedianImputer(imputation_method='median', variables=['BedroomAbvGr' , 'LotFrontage']) ),\n",
        "      ( 'CategoricalImputer', CategoricalImputer(imputation_method='missing', fill_value='Unf', variables=['BsmtFinType1', 'GarageFinish']) ),\n",
        "      \n",
        "])\n",
        "\n",
        "df = data_cleaning_pipeline.fit_transform(df)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* If you do not need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  # create here your folder\n",
        "  os.makedirs(name='outputs/datasets/cleaned')\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "# Save the Train Set\n",
        "TrainSet.to_csv(\"outputs/datasets/cleaned/TrainSetCleaned.csv\", index=False)\n",
        "\n",
        "# Save the Test Set\n",
        "TestSet.to_csv(\"outputs/datasets/cleaned/TestSetCleaned.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
